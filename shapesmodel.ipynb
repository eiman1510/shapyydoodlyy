{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "89195264d0e243169656215243fe84ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FileUploadModel",
          "model_module_version": "1.5.0",
          "state": {
            "_counter": 2,
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FileUploadModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "FileUploadView",
            "accept": "image/*",
            "button_style": "",
            "data": [
              null
            ],
            "description": "Upload",
            "description_tooltip": null,
            "disabled": false,
            "error": "",
            "icon": "upload",
            "layout": "IPY_MODEL_711ac43e9b8d4264b6d386bfb1cd9e72",
            "metadata": [
              {
                "name": "download.png",
                "type": "image/png",
                "size": 820,
                "lastModified": 1747485592996
              }
            ],
            "multiple": false,
            "style": "IPY_MODEL_e76b27677f2943cfb2ba1ec295e5138d"
          }
        },
        "711ac43e9b8d4264b6d386bfb1cd9e72": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e76b27677f2943cfb2ba1ec295e5138d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ts9Ur86TiXCl",
        "outputId": "df0453af-8dc0-445c-e5f2-2bcc20272085"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 11976 images belonging to 4 classes.\n",
            "Found 2994 images belonging to 4 classes.\n",
            "Epoch 1/10\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 159ms/step - accuracy: 0.8955 - loss: 0.2687 - val_accuracy: 1.0000 - val_loss: 6.7182e-04\n",
            "Epoch 2/10\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 139ms/step - accuracy: 0.9984 - loss: 0.0056 - val_accuracy: 1.0000 - val_loss: 9.4087e-06\n",
            "Epoch 3/10\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 140ms/step - accuracy: 0.9991 - loss: 0.0026 - val_accuracy: 1.0000 - val_loss: 5.1341e-07\n",
            "Epoch 4/10\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 140ms/step - accuracy: 0.9975 - loss: 0.0073 - val_accuracy: 1.0000 - val_loss: 4.9847e-07\n",
            "Epoch 5/10\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 138ms/step - accuracy: 0.9997 - loss: 0.0012 - val_accuracy: 1.0000 - val_loss: 3.7825e-09\n",
            "Epoch 6/10\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 144ms/step - accuracy: 0.9992 - loss: 0.0016 - val_accuracy: 1.0000 - val_loss: 5.9966e-07\n",
            "Epoch 7/10\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 157ms/step - accuracy: 0.9993 - loss: 0.0020 - val_accuracy: 1.0000 - val_loss: 1.0910e-08\n",
            "Epoch 8/10\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 160ms/step - accuracy: 0.9990 - loss: 0.0018 - val_accuracy: 1.0000 - val_loss: 8.4410e-09\n",
            "Epoch 9/10\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 156ms/step - accuracy: 1.0000 - loss: 4.2033e-04 - val_accuracy: 1.0000 - val_loss: 3.5834e-10\n",
            "Epoch 10/10\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 157ms/step - accuracy: 0.9998 - loss: 0.0012 - val_accuracy: 1.0000 - val_loss: 1.9064e-07\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 64ms/step - accuracy: 1.0000 - loss: 1.5829e-07\n",
            "\n",
            "Validation Accuracy: 1.00\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import kagglehub\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "# 0. Download and set dataset path\n",
        "base_path = kagglehub.dataset_download(\"smeschke/four-shapes\")\n",
        "dataset_path = os.path.join(base_path, \"shapes\")  # Make sure to point to the folder with class subfolders\n",
        "\n",
        "# 1. Data Preprocessing\n",
        "img_size = 64\n",
        "batch_size = 32\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    validation_split=0.2\n",
        ")\n",
        "\n",
        "train_generator = datagen.flow_from_directory(\n",
        "    dataset_path,\n",
        "    target_size=(img_size, img_size),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    subset='training',\n",
        "    shuffle=True,\n",
        "    seed=42\n",
        ")\n",
        "\n",
        "val_generator = datagen.flow_from_directory(\n",
        "    dataset_path,\n",
        "    target_size=(img_size, img_size),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    subset='validation',\n",
        "    shuffle=True,\n",
        "    seed=42\n",
        ")\n",
        "\n",
        "# 2. Build the CNN model\n",
        "model = Sequential([\n",
        "    tf.keras.Input(shape=(img_size, img_size, 3)),\n",
        "    Conv2D(32, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(2, 2),\n",
        "\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(2, 2),\n",
        "\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(4, activation='softmax')  # 4 classes: circle, triangle, star, square\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# 3. Train the model\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=10,\n",
        "    validation_data=val_generator\n",
        ")\n",
        "\n",
        "# 4. Evaluate the model\n",
        "val_loss, val_acc = model.evaluate(val_generator)\n",
        "print(f\"\\nValidation Accuracy: {val_acc:.2f}\")\n",
        "\n",
        "# 5. Prediction on a new image from file path\n",
        "def predict_image(img_path):\n",
        "    img = image.load_img(img_path, target_size=(img_size, img_size))\n",
        "    img_array = image.img_to_array(img)\n",
        "    img_array = np.expand_dims(img_array, axis=0) / 255.0\n",
        "\n",
        "    prediction = model.predict(img_array)\n",
        "    class_index = np.argmax(prediction)\n",
        "    class_labels = list(train_generator.class_indices.keys())\n",
        "\n",
        "    print(f\"Predicted shape: {class_labels[class_index]}\")\n",
        "\n",
        "# Example usage:\n",
        "# predict_image(\"path_to_new_image.png\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display\n",
        "import ipywidgets as widgets\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "\n",
        "def predict_uploaded_image(uploaded_file):\n",
        "    img = Image.open(BytesIO(uploaded_file['content'])).convert('RGB')\n",
        "    img = img.resize((img_size, img_size))\n",
        "    img_array = np.array(img) / 255.0\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "\n",
        "    prediction = model.predict(img_array)\n",
        "    class_index = np.argmax(prediction)\n",
        "    class_labels = list(train_generator.class_indices.keys())\n",
        "\n",
        "    display(img)\n",
        "    print(f\"Predicted shape: {class_labels[class_index]}\")\n",
        "\n",
        "uploader = widgets.FileUpload(accept='image/*', multiple=False)\n",
        "uploader.observe(lambda change: [predict_uploaded_image(file) for file in uploader.value.values()], names='value')\n",
        "display(uploader)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 149,
          "referenced_widgets": [
            "89195264d0e243169656215243fe84ac",
            "711ac43e9b8d4264b6d386bfb1cd9e72",
            "e76b27677f2943cfb2ba1ec295e5138d"
          ]
        },
        "id": "PT0eimZDmABf",
        "outputId": "e78bdd2f-86ba-46f2-8c4f-01e52d0898d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "FileUpload(value={}, accept='image/*', description='Upload')"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "89195264d0e243169656215243fe84ac"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=64x64>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAEAAAABACAIAAAAlC+aJAAADeElEQVR4Ae1aS08TURhtZ/p+Up59CQ0GSAj24YLCAhcS6sKNqXvlv/gD+AkuJcFgaCTVuEBrUhoKGxI3KA/pKxShndJC3/WYJm1i5xoW9ArJnTST2zMz93znnHvv6pM2Gg3JXb5kreLL5fKHYPAin/d4PJOTky38Pw6+7+3B3Xw+Pzzi6K1cCJzy05evNqvVbrcLguB0OlFbW0A6nd7d3X25uDg0NHR8fBxYW1Op1T6fL5lIuNzuzc1NCFtZWRkeHp6enl5dXcW9VCzu7Ow8np8fHx/vhk4hl4tEIrV645mSly+/0j55oTUY67Xa+vp7Tir9W4DNZvP7/cFg0OFwpFIp//PnW1tbGPzY33/gdEaj0bGxMbPZvLGxAQ31eh1/l5aWUHo4HO6SAIvFAgc5mVzx62fjvqcgZO/ZXVqdzmyxIJamZe0ECoXCwdGRyWTK5XLIKBQKHR0eTkxMFIvFQCDA8/z29nYikVAoFBhbrValUmk0Gk9OTmZnZrphP+aEp82Zo5lM1jGnlMskgnB2fo4acGH3SnG1NjFMjcfj2Amjo6Mcx8ViMSwbr9cLSdlstr+/X65QpJJJvcHQYzSWSiWVSgVtkDQ4OKjX67ukoTktVjwGIJXL5dVqtVn2wMAAwLYAPEY1kkajVq/jDpvhLqpExVhwkIf9xHMcBGOMKXCHTgx6+/ogsqsC/jF5ewnVarVMJoPqWm9jE+NvNpNpIZ0DyMCi7MSpIe0EqFHeLBF3s9PRn629hFrcWOVvlpfjySTPizxtvUZzUKlUHrpdvoWFTlKREmuV8uu377SPnmpwtjTaW6LzYzqIlONPk/H059B1BSABjcE44nRrNLrWIUunVlEWjufVpl71t7DoU5EE/ryHs7Jaxe82CGgWI1o9wDu/iZkAUrS0cJYALadJPCwBkjO0cJYALadJPCwBkjO0cJYALadJPCwBkjO0cJYALadJPCwBkjO0cJYALadJPCwBkjO0cJYALadJPCwBkjO0cJYALadJPCwBkjO0cJYALadJPCwBkjO0cJYALadJPCwBkjO0cJYALadJPCwBkjO0cEKvhBQtIugv429DrwTKQDXojhP1RFSA9Cp/cRqLqXX6WyGA58+ScdPV5XUFyBSKOdfUQeSjRKlER5roZzRBNFf2XF1OzXpFSVnPnKgtFEF2jFI0W5TqN9bfTFRxJf6wAAAAAElFTkSuQmCC\n",
            "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/2wBDAQkJCQwLDBgNDRgyIRwhMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjL/wAARCABAAEADASIAAhEBAxEB/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/8QAHwEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoL/8QAtREAAgECBAQDBAcFBAQAAQJ3AAECAxEEBSExBhJBUQdhcRMiMoEIFEKRobHBCSMzUvAVYnLRChYkNOEl8RcYGRomJygpKjU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6goOEhYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3uLm6wsPExcbHyMnK0tPU1dbX2Nna4uPk5ebn6Onq8vP09fb3+Pn6/9oADAMBAAIRAxEAPwD2fWWuY7m1kt7hIsBsrIzBD0wSF6kfl7VmpqOrmEr9qtw2WG6Q/N/EB0TB6oenY1t65dS2OgajdwECaC2kkQkZAYKSOPwriBruvFQf7V7f8+yf4VcKcp7GNWvClbm6nSWt1qklxZq+oWr5ceeip1G1eF49d/5j6V0Vedf27r3/AEFf/JZP8KP7d17/AKCv/ksn+FX7CZl9donotFedf27r3/QV/wDJZP8ACj+3de/6Cv8A5LJ/hR7CYfXaJ3d7bTXCoYLmSFkO7C4w/sfaqNlZ6nHeRyXN07oM71D5Vvlx0xx68YrkH17X1jZhqvIBP/Hsn+Fd5pdxJd6RZXMpBklgSRyBgZKgmonTcNzaliI1U1Eq+KP+RT1j/rym/wDQDXBL90fSu98Uf8inrH/XlN/6Aa4Jfuj6Vvhupw5h9n5i0UUV1HnBRRRQA2X/AFL/AO6f5V6HoX/IvaZ/16Rf+gCvPJf9S/8Aun+Veh6F/wAi9pn/AF6Rf+gCuXE9D0sv+18iLxR/yKesf9eU3/oBrgl+6PpXe+KP+RT1j/rym/8AQDXBL90fSjDdRZh9n5i0UUV1HnBRRRQA2X/Uv/un+Veh6F/yL2mf9ekX/oArzyX/AFL/AO6f5V6HoX/IvaZ/16Rf+gCuXE9D0sv+18iLxR/yKesf9eU3/oBrgl+6PpXpGp2Q1LSruxLmMXMLxFwM7dykZx+NcqPBF8AB/bcX/gF/9nUUakYXua4uhOrbl6GFRW9/whF9/wBBuL/wC/8As6P+EIvv+g3F/wCAX/2db+3gcf1KqYNFb3/CEX3/AEG4v/AL/wCzo/4Qi+/6DcX/AIBf/Z0e3gH1Kqc/L/qX/wB0/wAq9D0L/kXtM/69Iv8A0AVzTeB75lK/23FyMf8AHl/9nXW2NsLLT7a0DlxBEse4jGdoAz+lYVqkZ2sdmEoTpX5up//Z\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted shape: square\n"
          ]
        }
      ]
    }
  ]
}